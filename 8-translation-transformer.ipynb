{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is adapted from [this one](https://github.com/fastai/fastai_docs/blob/master/dev_course/dl2/translation_transformer.ipynb) created by Sylvain Gugger.\n",
    "\n",
    "See also [The Annotated Transformer](http://nlp.seas.harvard.edu/2018/04/03/attention.html) from Harvard NLP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention and the Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nvidia AI researcher [Chip Huyen](https://huyenchip.com/) wrote a great post [Top 8 trends from ICLR 2019](https://huyenchip.com/2019/05/12/top-8-trends-from-iclr-2019.html) in which one of the trends is that *RNN is losing its luster with researchers*.\n",
    "\n",
    "There's good reason for this, RNNs can be a pain: parallelization can be tricky and they can be difficult to debug. Since language is recursive, it seemed like RNNs were a good conceptual fit with NLP, but recently methods using *attention* have been achieving state of the art results on NLP.\n",
    "\n",
    "This is still an area of very active research, for instance, a recent paper [Pay Less Attention with Lightweight and Dynamic Convolutions](https://arxiv.org/abs/1901.10430) showed that convolutions can beat attention on some tasks, including English to German translation.  More research is needed on the various strenghts of RNNs, CNNs, and transformers/attention, and perhaps on approaches to combine the best of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/jhoward/.fastai/data/giga-fren/cc.en.300.bin'),\n",
       " PosixPath('/home/jhoward/.fastai/data/giga-fren/data_save.pkl'),\n",
       " PosixPath('/home/jhoward/.fastai/data/giga-fren/models'),\n",
       " PosixPath('/home/jhoward/.fastai/data/giga-fren/giga-fren.release2.fixed.en'),\n",
       " PosixPath('/home/jhoward/.fastai/data/giga-fren/giga-fren.release2.fixed.fr'),\n",
       " PosixPath('/home/jhoward/.fastai/data/giga-fren/questions_easy.csv'),\n",
       " PosixPath('/home/jhoward/.fastai/data/giga-fren/cc.fr.300.bin')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Config().data_path()/'giga-fren'\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reuse the same functions as in the translation notebook to load our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_collate(samples, pad_idx=1, pad_first=True, backwards=False):\n",
    "    \"Function that collect samples and adds padding. Flips token order if needed\"\n",
    "    samples = to_data(samples)\n",
    "    max_len_x,max_len_y = max([len(s[0]) for s in samples]),max([len(s[1]) for s in samples])\n",
    "    res_x = torch.zeros(len(samples), max_len_x).long() + pad_idx\n",
    "    res_y = torch.zeros(len(samples), max_len_y).long() + pad_idx\n",
    "    if backwards: pad_first = not pad_first\n",
    "    for i,s in enumerate(samples):\n",
    "        if pad_first: \n",
    "            res_x[i,-len(s[0]):],res_y[i,-len(s[1]):] = LongTensor(s[0]),LongTensor(s[1])\n",
    "        else:         \n",
    "            res_x[i, :len(s[0])],res_y[i, :len(s[1])] = LongTensor(s[0]),LongTensor(s[1])\n",
    "    if backwards: res_x,res_y = res_x.flip(1),res_y.flip(1)\n",
    "    return res_x, res_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqDataBunch(TextDataBunch):\n",
    "    \"Create a `TextDataBunch` suitable for training an RNN classifier.\"\n",
    "    @classmethod\n",
    "    def create(cls, train_ds, valid_ds, test_ds=None, path='.', bs=32, val_bs=None, pad_idx=1,\n",
    "               dl_tfms=None, pad_first=False, device=None, no_check=False, backwards=False, **dl_kwargs):\n",
    "        \"Function that transform the `datasets` in a `DataBunch` for classification. Passes `**dl_kwargs` on to `DataLoader()`\"\n",
    "        datasets = cls._init_ds(train_ds, valid_ds, test_ds)\n",
    "        val_bs = ifnone(val_bs, bs)\n",
    "        collate_fn = partial(seq2seq_collate, pad_idx=pad_idx, pad_first=pad_first, backwards=backwards)\n",
    "        train_sampler = SortishSampler(datasets[0].x, key=lambda t: len(datasets[0][t][0].data), bs=bs//2)\n",
    "        train_dl = DataLoader(datasets[0], batch_size=bs, sampler=train_sampler, drop_last=True, **dl_kwargs)\n",
    "        dataloaders = [train_dl]\n",
    "        for ds in datasets[1:]:\n",
    "            lengths = [len(t) for t in ds.x.items]\n",
    "            sampler = SortSampler(ds.x, key=lengths.__getitem__)\n",
    "            dataloaders.append(DataLoader(ds, batch_size=val_bs, sampler=sampler, **dl_kwargs))\n",
    "        return cls(*dataloaders, path=path, device=device, collate_fn=collate_fn, no_check=no_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqTextList(TextList):\n",
    "    _bunch = Seq2SeqDataBunch\n",
    "    _label_cls = TextList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer to notebook 7-seq2seq-translation for the code we used to create, process, and save this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>xxbos quelles questions devraient être traitées respectivement au niveau international et au niveau national , ou quelle xxunk devrait être établie entre la réglementation internationale et la réglementation nationale ?</td>\n",
       "      <td>xxbos which issues should be dealt with internationally and which nationally , or what division should be made between international regulation and national regulation ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos comment la culture et les arts y vivent - ils , et comment la société civile les prend - elle en considération dans le développement de la ville ?</td>\n",
       "      <td>xxbos where do art and culture fit in , and how is civil society taking them into consideration in developing the city ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos qu’arrivera - t - il si les entreprises canadiennes et les gouvernements ne se xxunk pas sur la question du conflit entre le travail et la vie personnelle ?</td>\n",
       "      <td>xxbos what will likely happen if canadian organizations and governments do not deal with the issue of work – life conflict ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos qu'adviendra - t - il de l'examen de rendement et de la rémunération au rendement de xxunk et comment se xxunk - t - il à cet égard ?</td>\n",
       "      <td>xxbos what happens to xxunk 's evaluation review and performance pay and how will this make him feel ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos quels avantages prévoit - on en général pour la région du delta de beaufort par suite de la signature de xxunk / d'une entente future sur l'autonomie gouvernementale ?</td>\n",
       "      <td>xxbos what benefits to the beaufort delta region generally are expected as a result of this aip / future self - government ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Transformer model](images/Transformer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shifting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add a transform to the dataloader that shifts the targets right and adds a padding at the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = data.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.stoi['xxpad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_tfm(b):\n",
    "    x,y = b\n",
    "    y = F.pad(y, (1, 0), value=1)\n",
    "    return [x,y[:,:-1]], y[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.add_tfm(shift_tfm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input and output embeddings are traditional PyTorch embeddings (and we can use pretrained vectors if we want to). The transformer model isn't a recurrent one, so it has no idea of the relative positions of the words. To help it with that, they had to the input embeddings a positional encoding which is cosine of a certain frequency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0667, 0.1333, 0.2000, 0.2667, 0.3333, 0.4000, 0.4667, 0.5333,\n",
       "        0.6000, 0.6667, 0.7333, 0.8000, 0.8667, 0.9333])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = 30\n",
    "torch.arange(0., d, 2.)/d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Module.register_buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Position Embedding论文公式：\n",
    "\\begin{cases}\n",
    "PE_{2i}(p)=sin(p/{10000^{2i/d_{model}}})\\\\\n",
    "PE_{2i+1}(p)=cos(p/{10000^{2i/d_{model}}})\\\\\n",
    "\\end{cases}\n",
    "这里的意思是将id为p的位置映射为一个$d_{model}$维的位置向量，这个向量的第i个元素的数值就是$PE_i(p)$。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"Encode the position with a sinusoid.\"\n",
    "    def __init__(self, d):\n",
    "        super().__init__()\n",
    "        self.register_buffer('freq', 1 / (10000 ** (torch.arange(0., d, 2.)/d)))\n",
    "    \n",
    "    def forward(self, pos):\n",
    "        inp = torch.ger(pos, self.freq)\n",
    "        enc = torch.cat([inp.sin(), inp.cos()], dim=-1)\n",
    "        return enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_encoding = PositionalEncoding(20)\n",
    "res = tst_encoding(torch.arange(0,100).float())\n",
    "_, ax = plt.subplots(1,1)\n",
    "for i in range(1,5): ax.plot(res[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEmbedding(nn.Module):\n",
    "    \"Embedding + positional encoding + dropout\"\n",
    "    def __init__(self, vocab_sz, emb_sz, inp_p=0.):\n",
    "        super().__init__()\n",
    "        self.emb_sz = emb_sz\n",
    "        self.embed = embedding(vocab_sz, emb_sz)\n",
    "        self.pos_enc = PositionalEncoding(emb_sz)\n",
    "        self.drop = nn.Dropout(inp_p)\n",
    "    \n",
    "    def forward(self, inp): \n",
    "        pos = torch.arange(0, inp.size(1), device=inp.device).float()\n",
    "        return self.drop(self.embed(inp) * math.sqrt(self.emb_sz) + self.pos_enc(pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Feed forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The feed forward cell is easy: it's just two linear layers with a skip connection and a LayerNorm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# MergeLayer的作用是将到这一步为止的结果和\n",
    "# SequentialEx的original输入进行合并(cat或相加)\n",
    "def feed_forward(d_model, d_ff, ff_p=0., double_drop=True):\n",
    "    layers = [nn.Linear(d_model, d_ff), nn.ReLU()]\n",
    "    if double_drop: layers.append(nn.Dropout(ff_p))\n",
    "    return SequentialEx(*layers, nn.Linear(d_ff, d_model), nn.Dropout(ff_p), \n",
    "                        MergeLayer(), nn.LayerNorm(d_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-head attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Multi head attention](images/attention.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, n_heads, d_model, d_head=None, p=0., bias=True, scale=True):\n",
    "        super().__init__()\n",
    "        d_head = ifnone(d_head, d_model//n_heads)\n",
    "        # n_heads-注意力头的个数, d_head-注意力头的维度, scale-是否有维度调整\n",
    "        self.n_heads, self.d_head, self.scale = n_heads, d_head, scale\n",
    "        # qkv三个向量生成（同时为多头生成向量）\n",
    "        self.q_wgt, self.k_wgt, self.v_wgt = [nn.Linear(\n",
    "            d_model, n_heads * d_head, bias=bias) for o in range(3)]\n",
    "        self.out = nn.Linear(n_heads * d_head, d_model, bias=bias)\n",
    "        self.drop_att, self.drop_res = nn.Dropout(p), nn.Dropout(p)\n",
    "        self.ln = nn.LayerNorm(d_model)\n",
    "        \n",
    "    def forward(self, q, kv, mask=None):\n",
    "        # add & norm\n",
    "        return self.ln(q + self.drop_res(self.out(self._apply_attention(q, kv, mask=mask))))\n",
    "    \n",
    "    def create_attn_mat(self, x, layer, bs):\n",
    "        # layer是qkv每个向量的生成层\n",
    "        # (bs, sequence_len, n_heads*d_head) => (bs, sequence_len, n_heads, d_head) \n",
    "        # => (bs, n_heads, sequence_len, d_head)\n",
    "        return layer(x).view(bs, x.size(1), self.n_heads, self.d_head\n",
    "                            ).permute(0, 2, 1, 3)\n",
    "    \n",
    "    def _apply_attention(self, q, kv, mask=None):\n",
    "        bs,seq_len = q.size(0),q.size(1)\n",
    "        # wq, wk, wv: (bs, n_heads, sequence_len, d_head)\n",
    "        wq, wk, wv = map(lambda o: self.create_attn_mat(*o,bs),\n",
    "                       zip((q,kv,kv),(self.q_wgt, self.k_wgt, self.v_wgt)))\n",
    "        # (bs, n_heads, sequence_len, d_head) @ (bs, n_heads, d_head, sequence_len)\n",
    "        # => (bs, n_heads, sequence_len, sequence_len)\n",
    "        attn_score = wq @ wk.transpose(2,3)\n",
    "        if self.scale: attn_score /= math.sqrt(self.d_head)\n",
    "        # 将padding的位置用负无穷填充，这样softmax时exp(-inf)=0\n",
    "        if mask is not None: \n",
    "            attn_score = attn_score.float().masked_fill(mask, -float('inf')).type_as(attn_score)\n",
    "        # (bs, n_heads, sequence_len, sequence_len) @ (bs, n_heads, sequence_len, d_head)\n",
    "        # => (bs, n_heads, sequence_len, d_head)\n",
    "        attn_prob = self.drop_att(F.softmax(attn_score, dim=-1))\n",
    "        attn_vec = attn_prob @ wv\n",
    "        # (bs, n_heads, sequence_len, d_head) => (bs, sequence_len, n_heads, d_head)\n",
    "        # => (bs, sequence_len, n_heads*d_head)\n",
    "        # contiguous一般在transpose、permute等变换操作之后使用，使得内存连续化\n",
    "        return attn_vec.permute(0, 2, 1, 3).contiguous().view(bs, seq_len, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Masking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The attention layer uses a mask to avoid paying attention to certain timesteps. The first thing is that we don't really want the network to pay attention to the padding, so we're going to mask it. The second thing is that since this model isn't recurrent, we need to mask (in the output) all the tokens we're not supposed to see yet (otherwise it would be cheating)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_output_mask(inp, pad_idx=1):\n",
    "    # torch.triu返回矩阵上三角，diagonal=x为轴位置（默认是主对角线0）\n",
    "    return torch.triu(inp.new_ones(inp.size(1),inp.size(1)), diagonal=1)[None,None].byte()\n",
    "#     return ((inp == pad_idx)[:,None,:,None].long() + torch.triu(inp.new_ones(inp.size(1),inp.size(1)), diagonal=1)[None,None] != 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Example of mask for the future tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 10, 10])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.triu(torch.ones(10,10), diagonal=1).byte()[None, None].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder and decoder blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to regroup these layers in the blocks we add in the model picture:\n",
    "\n",
    "![Transformer model](images/Transformer.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    \"Encoder block of a Transformer model.\"\n",
    "    #Can't use Sequential directly cause more than one input...\n",
    "    def __init__(self, n_heads, d_model, d_head, d_inner, p=0., bias=True, scale=True, double_drop=True):\n",
    "        super().__init__()\n",
    "        self.mha = MultiHeadAttention(n_heads, d_model, d_head, p=p, bias=bias, scale=scale)\n",
    "        self.ff  = feed_forward(d_model, d_inner, ff_p=p, double_drop=double_drop)\n",
    "    \n",
    "    def forward(self, x, mask=None): return self.ff(self.mha(x, x, mask=mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    \"Decoder block of a Transformer model.\"\n",
    "    #Can't use Sequential directly cause more than one input...\n",
    "    def __init__(self, n_heads, d_model, d_head, d_inner, p=0., bias=True, scale=True, double_drop=True):\n",
    "        super().__init__()\n",
    "        self.mha1 = MultiHeadAttention(n_heads, d_model, d_head, p=p, bias=bias, scale=scale)\n",
    "        self.mha2 = MultiHeadAttention(n_heads, d_model, d_head, p=p, bias=bias, scale=scale)\n",
    "        self.ff   = feed_forward(d_model, d_inner, ff_p=p, double_drop=double_drop)\n",
    "    \n",
    "    def forward(self, x, enc, mask_out=None): return self.ff(self.mha2(self.mha1(x, x, mask_out), enc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### The whole model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Transformer(Module):\n",
    "    def __init__(self, inp_vsz, out_vsz, n_layers=6, n_heads=8, d_model=256, d_head=32, \n",
    "                 d_inner=1024, p=0.1, bias=True, scale=True, double_drop=True, pad_idx=1):\n",
    "        self.enc_emb = TransformerEmbedding(inp_vsz, d_model, p)\n",
    "        self.dec_emb = TransformerEmbedding(out_vsz, d_model, 0.)\n",
    "        args = (n_heads, d_model, d_head, d_inner, p, bias, scale, double_drop)\n",
    "        self.encoder = nn.ModuleList([EncoderBlock(*args) for _ in range(n_layers)])\n",
    "        self.decoder = nn.ModuleList([DecoderBlock(*args) for _ in range(n_layers)])\n",
    "        self.out = nn.Linear(d_model, out_vsz)\n",
    "        self.out.weight = self.dec_emb.embed.weight\n",
    "        self.pad_idx = pad_idx\n",
    "        \n",
    "    def forward(self, inp, out):\n",
    "        mask_out = get_output_mask(out, self.pad_idx)\n",
    "        enc,out = self.enc_emb(inp),self.dec_emb(out)\n",
    "        enc = compose(self.encoder)(enc)\n",
    "        out = compose(self.decoder)(out, enc, mask_out)\n",
    "        return self.out(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Bleu metric (see dedicated notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class NGram():\n",
    "    def __init__(self, ngram, max_n=5000): self.ngram,self.max_n = ngram,max_n\n",
    "    def __eq__(self, other):\n",
    "        if len(self.ngram) != len(other.ngram): return False\n",
    "        return np.all(np.array(self.ngram) == np.array(other.ngram))\n",
    "    def __hash__(self): return int(sum([o * self.max_n**i for i,o in enumerate(self.ngram)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_grams(x, n, max_n=5000):\n",
    "    return x if n==1 else [NGram(x[i:i+n], max_n=max_n) for i in range(len(x)-n+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_correct_ngrams(pred, targ, n, max_n=5000):\n",
    "    pred_grams,targ_grams = get_grams(pred, n, max_n=max_n),get_grams(targ, n, max_n=max_n)\n",
    "    pred_cnt,targ_cnt = Counter(pred_grams),Counter(targ_grams)\n",
    "    return sum([min(c, targ_cnt[g]) for g,c in pred_cnt.items()]),len(pred_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class CorpusBLEU(Callback):\n",
    "    def __init__(self, vocab_sz):\n",
    "        self.vocab_sz = vocab_sz\n",
    "        self.name = 'bleu'\n",
    "    \n",
    "    def on_epoch_begin(self, **kwargs):\n",
    "        self.pred_len,self.targ_len,self.corrects,self.counts = 0,0,[0]*4,[0]*4\n",
    "    \n",
    "    def on_batch_end(self, last_output, last_target, **kwargs):\n",
    "        last_output = last_output.argmax(dim=-1)\n",
    "        for pred,targ in zip(last_output.cpu().numpy(),last_target.cpu().numpy()):\n",
    "            self.pred_len += len(pred)\n",
    "            self.targ_len += len(targ)\n",
    "            for i in range(4):\n",
    "                c,t = get_correct_ngrams(pred, targ, i+1, max_n=self.vocab_sz)\n",
    "                self.corrects[i] += c\n",
    "                self.counts[i]   += t\n",
    "    \n",
    "    def on_epoch_end(self, last_metrics, **kwargs):\n",
    "        precs = [c/t for c,t in zip(self.corrects,self.counts)]\n",
    "        len_penalty = exp(1 - self.targ_len/self.pred_len) if self.pred_len < self.targ_len else 1\n",
    "        bleu = len_penalty * ((precs[0]*precs[1]*precs[2]*precs[3]) ** 0.25)\n",
    "        return add_metrics(last_metrics, bleu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_x_vocab,n_y_vocab = len(data.train_ds.x.vocab.itos), len(data.train_ds.y.vocab.itos)\n",
    "\n",
    "model = Transformer(n_x_vocab, n_y_vocab, d_model=256)\n",
    "learn = Learner(data, model, metrics=[accuracy, CorpusBLEU(n_y_vocab)], loss_func = CrossEntropyFlat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>bleu</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.388738</td>\n",
       "      <td>2.521896</td>\n",
       "      <td>0.608056</td>\n",
       "      <td>0.440603</td>\n",
       "      <td>02:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.901857</td>\n",
       "      <td>1.958518</td>\n",
       "      <td>0.687528</td>\n",
       "      <td>0.504890</td>\n",
       "      <td>01:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.565219</td>\n",
       "      <td>1.652850</td>\n",
       "      <td>0.723345</td>\n",
       "      <td>0.536689</td>\n",
       "      <td>02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.306575</td>\n",
       "      <td>1.455323</td>\n",
       "      <td>0.747950</td>\n",
       "      <td>0.565299</td>\n",
       "      <td>02:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.137455</td>\n",
       "      <td>1.342423</td>\n",
       "      <td>0.764108</td>\n",
       "      <td>0.587329</td>\n",
       "      <td>02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.949592</td>\n",
       "      <td>1.282115</td>\n",
       "      <td>0.774509</td>\n",
       "      <td>0.601252</td>\n",
       "      <td>02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.808173</td>\n",
       "      <td>1.269965</td>\n",
       "      <td>0.778810</td>\n",
       "      <td>0.607137</td>\n",
       "      <td>01:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.767959</td>\n",
       "      <td>1.274921</td>\n",
       "      <td>0.778822</td>\n",
       "      <td>0.607116</td>\n",
       "      <td>01:51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(8, 5e-4, div_factor=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(learn, ds_type=DatasetType.Valid):\n",
    "    learn.model.eval()\n",
    "    inputs, targets, outputs = [],[],[]\n",
    "    with torch.no_grad():\n",
    "        for xb,yb in progress_bar(learn.dl(ds_type)):\n",
    "            out = learn.model(*xb)\n",
    "            for x,y,z in zip(xb[0],xb[1],out):\n",
    "                inputs.append(learn.data.train_ds.x.reconstruct(x))\n",
    "                targets.append(learn.data.train_ds.y.reconstruct(y))\n",
    "                outputs.append(learn.data.train_ds.y.reconstruct(z.argmax(1)))\n",
    "    return inputs, targets, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='149' class='' max='149', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [149/149 00:28<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs, targets, outputs = get_predictions(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Text xxbos xxmaj pendant que xxunk les activités requises pour maintenir mon xxunk physique , est - ce que je xxunk de la protection d’un régime d’assurance ou de pension ?,\n",
       " Text xxbos xxmaj while i go about maintaining this high degree of fitness , am i protected under an insurance or pension plan ?,\n",
       " Text xxbos xxmaj while i do to the my physical physical of physical , do i aware by the pension plan service plan ?)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[10],targets[10],outputs[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Text xxbos xxmaj quelles sont les conséquences sur la recherche , la mise en pratique et les politiques en ce qui a trait à l'ac ?,\n",
       " Text xxbos xxmaj what are the xxunk for xxup kt research , practice / policy ?,\n",
       " Text xxbos xxmaj what are the implications implications research kt , , policy and policies in)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[700],targets[700],outputs[700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Text xxbos xxmaj quelle est la position des xxmaj états - xxmaj unis , du xxmaj canada et de la xxup xxunk à ce propos ?,\n",
       " Text xxbos xxmaj where do the xxup us , xxmaj canada and xxup xxunk stand ?,\n",
       " Text xxbos xxmaj what is xxmaj xxup us xxmaj xxmaj united and the xxunk fit in)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[701],targets[701],outputs[701]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Text xxbos xxmaj quels sont les atouts particuliers du xxmaj canada en recherche sur l'obésité sur la scène internationale ?,\n",
       " Text xxbos xxmaj what are the unique xxmaj canadian strengths in obesity research that set xxmaj canada apart on an international front ?,\n",
       " Text xxbos xxmaj what are xxmaj specific strengths canada strengths in obesity - ? are up canada ? from international international stage ?)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[2500],targets[2500],outputs[2500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Text xxbos xxmaj quelles sont les répercussions politiques à long terme de cette révolution scientifique mondiale ?,\n",
       " Text xxbos xxmaj what are some of the long - term policy implications of this global knowledge revolution ?,\n",
       " Text xxbos xxmaj what are the long the long - term policies implications of this global scientific ? ?)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[4002],targets[4002],outputs[4002]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They point out in the paper that using label smoothing helped getting a better BLEU/accuracy, even if it made the loss worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(len(data.train_ds.x.vocab.itos), len(data.train_ds.y.vocab.itos), d_model=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(data, model, metrics=[accuracy, CorpusBLEU(len(data.train_ds.y.vocab.itos))], \n",
    "                loss_func=FlattenedLoss(LabelSmoothingCrossEntropy, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>bleu</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.281034</td>\n",
       "      <td>3.357356</td>\n",
       "      <td>0.621848</td>\n",
       "      <td>0.458009</td>\n",
       "      <td>01:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.872045</td>\n",
       "      <td>2.923340</td>\n",
       "      <td>0.690921</td>\n",
       "      <td>0.510376</td>\n",
       "      <td>01:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.598603</td>\n",
       "      <td>2.653438</td>\n",
       "      <td>0.729291</td>\n",
       "      <td>0.545735</td>\n",
       "      <td>01:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.407944</td>\n",
       "      <td>2.514847</td>\n",
       "      <td>0.748187</td>\n",
       "      <td>0.567057</td>\n",
       "      <td>01:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.195246</td>\n",
       "      <td>2.403729</td>\n",
       "      <td>0.766409</td>\n",
       "      <td>0.592165</td>\n",
       "      <td>01:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.095695</td>\n",
       "      <td>2.362098</td>\n",
       "      <td>0.776127</td>\n",
       "      <td>0.604666</td>\n",
       "      <td>01:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.999303</td>\n",
       "      <td>2.358647</td>\n",
       "      <td>0.779535</td>\n",
       "      <td>0.609675</td>\n",
       "      <td>01:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.923621</td>\n",
       "      <td>2.359421</td>\n",
       "      <td>0.780211</td>\n",
       "      <td>0.610871</td>\n",
       "      <td>01:47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(8, 5e-4, div_factor=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(8, 5e-4, div_factor=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quels sont les atouts particuliers du Canada en recherche sur l'obésité sur la scène internationale ?\n",
      "What are Specific strengths canada strengths in obesity - ? are up canada ? from international international stage ?\n",
      "Quelles sont les répercussions politiques à long terme de cette révolution scientifique mondiale ?\n",
      "What are the long the long - term policies implications of this global scientific ? ?\n"
     ]
    }
   ],
   "source": [
    "print(\"Quels sont les atouts particuliers du Canada en recherche sur l'obésité sur la scène internationale ?\")\n",
    "print(\"What are Specific strengths canada strengths in obesity - ? are up canada ? from international international stage ?\")\n",
    "print(\"Quelles sont les répercussions politiques à long terme de cette révolution scientifique mondiale ?\")\n",
    "print(\"What are the long the long - term policies implications of this global scientific ? ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Text xxbos xxmaj quelle distance y a - t - il entre le point le plus rapproché de la surface à xxunk et la position d’utilisation habituelle du tube radiogène ?,\n",
       " Text xxbos xxmaj what is the distance between the nearest point of the area to be shielded and the usual operational position of the x - ray tube ?,\n",
       " Text xxbos xxmaj what is the xxmaj between the xxmaj and of the xxmaj ? the ? and the most ? ? of the xxmaj - ray tube ?)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[10],targets[10],outputs[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Text xxbos xxmaj quels types de présentations xxmaj santé xxmaj canada xxunk - t - il dans le format ectd à compter du 1er septembre ?,\n",
       " Text xxbos xxmaj what kind of submission types will xxmaj health xxmaj canada accept on xxmaj september 1 , 2004 in ectd format ?,\n",
       " Text xxbos xxmaj what is of information is of be canadian xxmaj canada take ? the canadian ? , and ? the format ?)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[700],targets[700],outputs[700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Text xxbos xxmaj quelles sont les trois caractéristiques qui vous incitent le plus à investir dans votre région ( xxup nommez - xxup les ) ?,\n",
       " Text xxbos xxmaj what are the three most attractive features about investing in your region ( xxup name xxup it ) ?,\n",
       " Text xxbos xxmaj what is the main main important concerns of the in the country ? xxup xxunk , xxunk ) ?)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[701],targets[701],outputs[701]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Text xxbos xxmaj quelles actions avez - vous prises et quel en a été le résultat ?,\n",
       " Text xxbos xxmaj what were your actions and the outcomes ?,\n",
       " Text xxbos xxmaj what is the targets ? how main of)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[4001],targets[4001],outputs[4001]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test leakage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we change a token in the targets at position n, it shouldn't impact the predictions before that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb,yb = data.one_batch(cpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp1,out1 = xb[0][:1],xb[1][:1]\n",
    "inp2,out2 = inp1.clone(),out1.clone()\n",
    "out2[0,15] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = learn.model(inp1, out1)\n",
    "y2 = learn.model(inp2, out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., device='cuda:0', grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y1[0,:15] - y2[0,:15]).abs().mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
